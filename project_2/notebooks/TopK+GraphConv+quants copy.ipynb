{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 150)\n",
      "(150, 150)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GraphConv, TopKPooling, MLP, GINEConv\n",
    "from torch_geometric.nn import global_max_pool as gmp\n",
    "from torch_geometric.nn import global_mean_pool as gap\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import utils\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "train_dataset = utils.GraphDataset(\"../data/\", \"GunPoint\", True, n_quantiles=25)\n",
    "train_loader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
    "\n",
    "test_dataset = utils.GraphDataset(\"../data/\", \"GunPoint\", False, n_quantiles=25)\n",
    "test_loader = DataLoader(test_dataset, batch_size=int(len(test_dataset) / 2) + 1)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        nn = MLP([1, 32])\n",
    "        self.conv1 = GINEConv(nn, edge_dim=1)\n",
    "        self.pool1 = TopKPooling(32, ratio=0.8)\n",
    "        nn = MLP([32, 32])\n",
    "        self.conv2 = GINEConv(nn, edge_dim=1)\n",
    "        self.pool2 = TopKPooling(32, ratio=0.8)\n",
    "        nn = MLP([32, 32])\n",
    "        self.conv3 = GINEConv(nn, edge_dim=1)\n",
    "        self.pool3 = TopKPooling(32, ratio=0.8)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, 16)\n",
    "        self.lin3 = torch.nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch, edge_weight = (\n",
    "            data.x,\n",
    "            data.edge_index,\n",
    "            data.batch,\n",
    "            data.edge_weight,\n",
    "        )\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_weight))\n",
    "        x, edge_index, edge_weight, batch, _, _ = self.pool1(\n",
    "            x, edge_index, edge_weight, batch\n",
    "        )\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_weight))\n",
    "        x, edge_index, edge_weight, batch, _, _ = self.pool2(\n",
    "            x, edge_index, edge_weight, batch\n",
    "        )\n",
    "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv3(x, edge_index, edge_weight))\n",
    "        x, edge_index, edge_weight, batch, _, _ = self.pool3(\n",
    "            x, edge_index, edge_weight, batch\n",
    "        )\n",
    "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = x1 + x2 + x3\n",
    "\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = F.log_softmax(self.lin3(x), dim=-1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, patience=5, mode=\"min\", cooldown=1, factor=0.5, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_out = model(data)\n",
    "        loss = F.nll_loss(y_out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    loss = 0\n",
    "    for data in loader:\n",
    "        y_out = model(data)\n",
    "        y_pred.append(y_out.argmax(dim=-1))\n",
    "        y_true.append(data.y)\n",
    "        loss += float(F.nll_loss(y_out, data.y) * data.num_graphs)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    y_true = np.concatenate(y_true)\n",
    "    return (\n",
    "        f1_score(y_true=y_true, y_pred=y_pred, average=\"macro\"),\n",
    "        accuracy_score(y_true=y_true, y_pred=y_pred),\n",
    "        loss / len(loader.dataset),\n",
    "    )\n",
    "\n",
    "\n",
    "best_val_acc = test_acc = 0\n",
    "best_val_loss = float(\"inf\")\n",
    "patience = start_patience = 50\n",
    "best_macro_f1 = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train_Loss: 0.6932,Test_Loss: 0.6927,Train_f1: 0.4346,Test_f1: 0.3791,Train_acc: 0.5000,Test_acc: 0.5067\n",
      "Epoch: 001, Train_Loss: 0.6928,Test_Loss: 0.6923,Train_f1: 0.4419,Test_f1: 0.4268,Train_acc: 0.4600,Test_acc: 0.5067\n",
      "Epoch: 002, Train_Loss: 0.6922,Test_Loss: 0.6919,Train_f1: 0.4800,Test_f1: 0.5172,Train_acc: 0.4800,Test_acc: 0.5267\n",
      "Epoch: 003, Train_Loss: 0.6917,Test_Loss: 0.6915,Train_f1: 0.5074,Test_f1: 0.5798,Train_acc: 0.5200,Test_acc: 0.5800\n",
      "Epoch: 004, Train_Loss: 0.6913,Test_Loss: 0.6912,Train_f1: 0.5924,Test_f1: 0.5819,Train_acc: 0.6200,Test_acc: 0.5867\n",
      "Epoch: 005, Train_Loss: 0.6909,Test_Loss: 0.6908,Train_f1: 0.4286,Test_f1: 0.5102,Train_acc: 0.5200,Test_acc: 0.5400\n",
      "Epoch: 006, Train_Loss: 0.6904,Test_Loss: 0.6904,Train_f1: 0.4283,Test_f1: 0.5098,Train_acc: 0.5600,Test_acc: 0.5600\n",
      "Epoch: 007, Train_Loss: 0.6899,Test_Loss: 0.6901,Train_f1: 0.3867,Test_f1: 0.4329,Train_acc: 0.5400,Test_acc: 0.5267\n",
      "Epoch: 008, Train_Loss: 0.6896,Test_Loss: 0.6900,Train_f1: 0.3421,Test_f1: 0.4211,Train_acc: 0.5200,Test_acc: 0.5200\n",
      "Epoch: 009, Train_Loss: 0.6894,Test_Loss: 0.6898,Train_f1: 0.3421,Test_f1: 0.3882,Train_acc: 0.5200,Test_acc: 0.5067\n",
      "Epoch: 010, Train_Loss: 0.6891,Test_Loss: 0.6896,Train_f1: 0.3421,Test_f1: 0.3489,Train_acc: 0.5200,Test_acc: 0.4867\n",
      "Epoch: 011, Train_Loss: 0.6888,Test_Loss: 0.6895,Train_f1: 0.3421,Test_f1: 0.3416,Train_acc: 0.5200,Test_acc: 0.4933\n",
      "Epoch: 012, Train_Loss: 0.6886,Test_Loss: 0.6893,Train_f1: 0.3421,Test_f1: 0.3274,Train_acc: 0.5200,Test_acc: 0.4867\n",
      "Epoch: 013, Train_Loss: 0.6884,Test_Loss: 0.6892,Train_f1: 0.3421,Test_f1: 0.3304,Train_acc: 0.5200,Test_acc: 0.4933\n",
      "Epoch: 014, Train_Loss: 0.6882,Test_Loss: 0.6890,Train_f1: 0.3421,Test_f1: 0.3304,Train_acc: 0.5200,Test_acc: 0.4933\n",
      "Epoch: 015, Train_Loss: 0.6881,Test_Loss: 0.6888,Train_f1: 0.3421,Test_f1: 0.3304,Train_acc: 0.5200,Test_acc: 0.4933\n",
      "Epoch: 016, Train_Loss: 0.6880,Test_Loss: 0.6886,Train_f1: 0.3421,Test_f1: 0.3304,Train_acc: 0.5200,Test_acc: 0.4933\n",
      "Epoch: 017, Train_Loss: 0.6879,Test_Loss: 0.6885,Train_f1: 0.3421,Test_f1: 0.3304,Train_acc: 0.5200,Test_acc: 0.4933\n",
      "Epoch: 018, Train_Loss: 0.6877,Test_Loss: 0.6881,Train_f1: 0.3421,Test_f1: 0.3304,Train_acc: 0.5200,Test_acc: 0.4933\n",
      "Epoch: 019, Train_Loss: 0.6874,Test_Loss: 0.6878,Train_f1: 0.3421,Test_f1: 0.3304,Train_acc: 0.5200,Test_acc: 0.4933\n",
      "Epoch: 020, Train_Loss: 0.6871,Test_Loss: 0.6875,Train_f1: 0.3421,Test_f1: 0.3304,Train_acc: 0.5200,Test_acc: 0.4933\n",
      "Epoch: 021, Train_Loss: 0.6868,Test_Loss: 0.6872,Train_f1: 0.3421,Test_f1: 0.3304,Train_acc: 0.5200,Test_acc: 0.4933\n",
      "Epoch: 022, Train_Loss: 0.6863,Test_Loss: 0.6869,Train_f1: 0.3421,Test_f1: 0.3304,Train_acc: 0.5200,Test_acc: 0.4933\n",
      "Epoch: 023, Train_Loss: 0.6857,Test_Loss: 0.6864,Train_f1: 0.3421,Test_f1: 0.3304,Train_acc: 0.5200,Test_acc: 0.4933\n",
      "Epoch: 024, Train_Loss: 0.6848,Test_Loss: 0.6859,Train_f1: 0.3421,Test_f1: 0.3304,Train_acc: 0.5200,Test_acc: 0.4933\n",
      "Epoch: 025, Train_Loss: 0.6840,Test_Loss: 0.6853,Train_f1: 0.3421,Test_f1: 0.3304,Train_acc: 0.5200,Test_acc: 0.4933\n",
      "Epoch: 026, Train_Loss: 0.6835,Test_Loss: 0.6848,Train_f1: 0.3421,Test_f1: 0.3304,Train_acc: 0.5200,Test_acc: 0.4933\n",
      "Epoch: 027, Train_Loss: 0.6829,Test_Loss: 0.6841,Train_f1: 0.3421,Test_f1: 0.3304,Train_acc: 0.5200,Test_acc: 0.4933\n",
      "Epoch: 028, Train_Loss: 0.6825,Test_Loss: 0.6837,Train_f1: 0.3421,Test_f1: 0.3304,Train_acc: 0.5200,Test_acc: 0.4933\n",
      "Epoch: 029, Train_Loss: 0.6822,Test_Loss: 0.6833,Train_f1: 0.3421,Test_f1: 0.3304,Train_acc: 0.5200,Test_acc: 0.4933\n",
      "Epoch: 030, Train_Loss: 0.6821,Test_Loss: 0.6830,Train_f1: 0.3421,Test_f1: 0.3274,Train_acc: 0.5200,Test_acc: 0.4867\n",
      "Epoch: 031, Train_Loss: 0.6819,Test_Loss: 0.6827,Train_f1: 0.3421,Test_f1: 0.3352,Train_acc: 0.5200,Test_acc: 0.4800\n",
      "Epoch: 032, Train_Loss: 0.6817,Test_Loss: 0.6823,Train_f1: 0.3421,Test_f1: 0.3516,Train_acc: 0.5200,Test_acc: 0.4733\n",
      "Epoch: 033, Train_Loss: 0.6814,Test_Loss: 0.6819,Train_f1: 0.3421,Test_f1: 0.4199,Train_acc: 0.5200,Test_acc: 0.5067\n",
      "Epoch: 034, Train_Loss: 0.6812,Test_Loss: 0.6815,Train_f1: 0.4165,Test_f1: 0.4241,Train_acc: 0.5400,Test_acc: 0.4933\n",
      "Epoch: 035, Train_Loss: 0.6808,Test_Loss: 0.6810,Train_f1: 0.4165,Test_f1: 0.4702,Train_acc: 0.5400,Test_acc: 0.5200\n",
      "Epoch: 036, Train_Loss: 0.6802,Test_Loss: 0.6803,Train_f1: 0.4544,Test_f1: 0.5029,Train_acc: 0.5600,Test_acc: 0.5400\n",
      "Epoch: 037, Train_Loss: 0.6797,Test_Loss: 0.6797,Train_f1: 0.4624,Test_f1: 0.5190,Train_acc: 0.5400,Test_acc: 0.5467\n",
      "Epoch: 038, Train_Loss: 0.6791,Test_Loss: 0.6791,Train_f1: 0.4485,Test_f1: 0.5278,Train_acc: 0.5200,Test_acc: 0.5467\n",
      "Epoch: 039, Train_Loss: 0.6786,Test_Loss: 0.6785,Train_f1: 0.4485,Test_f1: 0.5246,Train_acc: 0.5200,Test_acc: 0.5400\n",
      "Epoch: 040, Train_Loss: 0.6779,Test_Loss: 0.6778,Train_f1: 0.4346,Test_f1: 0.5211,Train_acc: 0.5000,Test_acc: 0.5333\n",
      "Epoch: 041, Train_Loss: 0.6772,Test_Loss: 0.6773,Train_f1: 0.4505,Test_f1: 0.5211,Train_acc: 0.5000,Test_acc: 0.5333\n",
      "Epoch: 042, Train_Loss: 0.6764,Test_Loss: 0.6766,Train_f1: 0.4358,Test_f1: 0.5211,Train_acc: 0.4800,Test_acc: 0.5333\n",
      "Epoch: 043, Train_Loss: 0.6757,Test_Loss: 0.6760,Train_f1: 0.4505,Test_f1: 0.5211,Train_acc: 0.5000,Test_acc: 0.5333\n",
      "Epoch: 044, Train_Loss: 0.6750,Test_Loss: 0.6755,Train_f1: 0.4207,Test_f1: 0.5051,Train_acc: 0.4800,Test_acc: 0.5200\n",
      "Epoch: 045, Train_Loss: 0.6743,Test_Loss: 0.6749,Train_f1: 0.4346,Test_f1: 0.4806,Train_acc: 0.5000,Test_acc: 0.5000\n",
      "Epoch: 046, Train_Loss: 0.6737,Test_Loss: 0.6745,Train_f1: 0.4485,Test_f1: 0.4831,Train_acc: 0.5200,Test_acc: 0.5067\n",
      "Epoch: 047, Train_Loss: 0.6733,Test_Loss: 0.6739,Train_f1: 0.4485,Test_f1: 0.4777,Train_acc: 0.5200,Test_acc: 0.5000\n",
      "Epoch: 048, Train_Loss: 0.6729,Test_Loss: 0.6734,Train_f1: 0.4485,Test_f1: 0.4831,Train_acc: 0.5200,Test_acc: 0.5067\n",
      "Epoch: 049, Train_Loss: 0.6723,Test_Loss: 0.6728,Train_f1: 0.4346,Test_f1: 0.4806,Train_acc: 0.5000,Test_acc: 0.5000\n",
      "Epoch: 050, Train_Loss: 0.6718,Test_Loss: 0.6722,Train_f1: 0.4346,Test_f1: 0.4806,Train_acc: 0.5000,Test_acc: 0.5000\n",
      "Epoch: 051, Train_Loss: 0.6714,Test_Loss: 0.6716,Train_f1: 0.4485,Test_f1: 0.4777,Train_acc: 0.5200,Test_acc: 0.5000\n",
      "Epoch: 052, Train_Loss: 0.6708,Test_Loss: 0.6709,Train_f1: 0.4485,Test_f1: 0.4692,Train_acc: 0.5200,Test_acc: 0.4933\n",
      "Epoch: 053, Train_Loss: 0.6700,Test_Loss: 0.6702,Train_f1: 0.4346,Test_f1: 0.4806,Train_acc: 0.5000,Test_acc: 0.5000\n",
      "Epoch: 054, Train_Loss: 0.6691,Test_Loss: 0.6693,Train_f1: 0.4066,Test_f1: 0.4914,Train_acc: 0.4600,Test_acc: 0.5067\n",
      "Epoch: 055, Train_Loss: 0.6683,Test_Loss: 0.6685,Train_f1: 0.4746,Test_f1: 0.4842,Train_acc: 0.5000,Test_acc: 0.4933\n",
      "Epoch: 056, Train_Loss: 0.6674,Test_Loss: 0.6675,Train_f1: 0.4419,Test_f1: 0.4859,Train_acc: 0.4600,Test_acc: 0.4933\n",
      "Epoch: 057, Train_Loss: 0.6664,Test_Loss: 0.6664,Train_f1: 0.4663,Test_f1: 0.5256,Train_acc: 0.4800,Test_acc: 0.5267\n",
      "Epoch: 058, Train_Loss: 0.6653,Test_Loss: 0.6653,Train_f1: 0.4663,Test_f1: 0.5400,Train_acc: 0.4800,Test_acc: 0.5400\n",
      "Epoch: 059, Train_Loss: 0.6641,Test_Loss: 0.6641,Train_f1: 0.4492,Test_f1: 0.5587,Train_acc: 0.4600,Test_acc: 0.5600\n",
      "Epoch: 060, Train_Loss: 0.6630,Test_Loss: 0.6631,Train_f1: 0.4492,Test_f1: 0.5524,Train_acc: 0.4600,Test_acc: 0.5533\n",
      "Epoch: 061, Train_Loss: 0.6620,Test_Loss: 0.6621,Train_f1: 0.4724,Test_f1: 0.5524,Train_acc: 0.4800,Test_acc: 0.5533\n",
      "Epoch: 062, Train_Loss: 0.6609,Test_Loss: 0.6609,Train_f1: 0.4724,Test_f1: 0.5587,Train_acc: 0.4800,Test_acc: 0.5600\n",
      "Epoch: 063, Train_Loss: 0.6599,Test_Loss: 0.6598,Train_f1: 0.4949,Test_f1: 0.5587,Train_acc: 0.5000,Test_acc: 0.5600\n",
      "Epoch: 064, Train_Loss: 0.6587,Test_Loss: 0.6586,Train_f1: 0.4949,Test_f1: 0.5587,Train_acc: 0.5000,Test_acc: 0.5600\n",
      "Epoch: 065, Train_Loss: 0.6573,Test_Loss: 0.6574,Train_f1: 0.4949,Test_f1: 0.5651,Train_acc: 0.5000,Test_acc: 0.5667\n",
      "Epoch: 066, Train_Loss: 0.6559,Test_Loss: 0.6560,Train_f1: 0.4949,Test_f1: 0.5651,Train_acc: 0.5000,Test_acc: 0.5667\n",
      "Epoch: 067, Train_Loss: 0.6546,Test_Loss: 0.6547,Train_f1: 0.4949,Test_f1: 0.5651,Train_acc: 0.5000,Test_acc: 0.5667\n",
      "Epoch: 068, Train_Loss: 0.6532,Test_Loss: 0.6534,Train_f1: 0.4949,Test_f1: 0.5509,Train_acc: 0.5000,Test_acc: 0.5533\n",
      "Epoch: 069, Train_Loss: 0.6518,Test_Loss: 0.6522,Train_f1: 0.4949,Test_f1: 0.5509,Train_acc: 0.5000,Test_acc: 0.5533\n",
      "Epoch: 070, Train_Loss: 0.6502,Test_Loss: 0.6506,Train_f1: 0.4949,Test_f1: 0.5500,Train_acc: 0.5000,Test_acc: 0.5533\n",
      "Epoch: 071, Train_Loss: 0.6481,Test_Loss: 0.6487,Train_f1: 0.4982,Test_f1: 0.5623,Train_acc: 0.5000,Test_acc: 0.5667\n",
      "Epoch: 072, Train_Loss: 0.6461,Test_Loss: 0.6468,Train_f1: 0.4982,Test_f1: 0.5867,Train_acc: 0.5000,Test_acc: 0.5933\n",
      "Epoch: 073, Train_Loss: 0.6441,Test_Loss: 0.6449,Train_f1: 0.4982,Test_f1: 0.5988,Train_acc: 0.5000,Test_acc: 0.6067\n",
      "Epoch: 074, Train_Loss: 0.6421,Test_Loss: 0.6431,Train_f1: 0.4982,Test_f1: 0.6032,Train_acc: 0.5000,Test_acc: 0.6133\n",
      "Epoch: 075, Train_Loss: 0.6400,Test_Loss: 0.6413,Train_f1: 0.5192,Test_f1: 0.6091,Train_acc: 0.5200,Test_acc: 0.6200\n",
      "Epoch: 076, Train_Loss: 0.6381,Test_Loss: 0.6395,Train_f1: 0.5192,Test_f1: 0.6151,Train_acc: 0.5200,Test_acc: 0.6267\n",
      "Epoch: 077, Train_Loss: 0.6364,Test_Loss: 0.6379,Train_f1: 0.5398,Test_f1: 0.6151,Train_acc: 0.5400,Test_acc: 0.6267\n",
      "Epoch: 078, Train_Loss: 0.6351,Test_Loss: 0.6365,Train_f1: 0.5600,Test_f1: 0.6151,Train_acc: 0.5600,Test_acc: 0.6267\n",
      "Epoch: 079, Train_Loss: 0.6338,Test_Loss: 0.6350,Train_f1: 0.5798,Test_f1: 0.6151,Train_acc: 0.5800,Test_acc: 0.6267\n",
      "Epoch: 080, Train_Loss: 0.6328,Test_Loss: 0.6337,Train_f1: 0.5798,Test_f1: 0.6151,Train_acc: 0.5800,Test_acc: 0.6267\n",
      "Epoch: 081, Train_Loss: 0.6314,Test_Loss: 0.6324,Train_f1: 0.5798,Test_f1: 0.6151,Train_acc: 0.5800,Test_acc: 0.6267\n",
      "Epoch: 082, Train_Loss: 0.6302,Test_Loss: 0.6312,Train_f1: 0.5798,Test_f1: 0.6270,Train_acc: 0.5800,Test_acc: 0.6400\n",
      "Epoch: 083, Train_Loss: 0.6287,Test_Loss: 0.6298,Train_f1: 0.5994,Test_f1: 0.6389,Train_acc: 0.6000,Test_acc: 0.6533\n",
      "Epoch: 084, Train_Loss: 0.6268,Test_Loss: 0.6280,Train_f1: 0.5994,Test_f1: 0.6389,Train_acc: 0.6000,Test_acc: 0.6533\n",
      "Epoch: 085, Train_Loss: 0.6246,Test_Loss: 0.6261,Train_f1: 0.6186,Test_f1: 0.6389,Train_acc: 0.6200,Test_acc: 0.6533\n",
      "Epoch: 086, Train_Loss: 0.6222,Test_Loss: 0.6241,Train_f1: 0.6566,Test_f1: 0.6448,Train_acc: 0.6600,Test_acc: 0.6600\n",
      "Epoch: 087, Train_Loss: 0.6198,Test_Loss: 0.6221,Train_f1: 0.6753,Test_f1: 0.6448,Train_acc: 0.6800,Test_acc: 0.6600\n",
      "Epoch: 088, Train_Loss: 0.6176,Test_Loss: 0.6201,Train_f1: 0.6940,Test_f1: 0.6448,Train_acc: 0.7000,Test_acc: 0.6600\n",
      "Epoch: 089, Train_Loss: 0.6154,Test_Loss: 0.6179,Train_f1: 0.6940,Test_f1: 0.6448,Train_acc: 0.7000,Test_acc: 0.6600\n",
      "Epoch: 090, Train_Loss: 0.6129,Test_Loss: 0.6156,Train_f1: 0.6940,Test_f1: 0.6448,Train_acc: 0.7000,Test_acc: 0.6600\n",
      "Epoch: 091, Train_Loss: 0.6110,Test_Loss: 0.6140,Train_f1: 0.6940,Test_f1: 0.6448,Train_acc: 0.7000,Test_acc: 0.6600\n",
      "Epoch: 092, Train_Loss: 0.6092,Test_Loss: 0.6124,Train_f1: 0.6940,Test_f1: 0.6448,Train_acc: 0.7000,Test_acc: 0.6600\n",
      "Epoch: 093, Train_Loss: 0.6075,Test_Loss: 0.6108,Train_f1: 0.6940,Test_f1: 0.6448,Train_acc: 0.7000,Test_acc: 0.6600\n",
      "Epoch: 094, Train_Loss: 0.6055,Test_Loss: 0.6091,Train_f1: 0.6940,Test_f1: 0.6448,Train_acc: 0.7000,Test_acc: 0.6600\n",
      "Epoch: 095, Train_Loss: 0.6033,Test_Loss: 0.6073,Train_f1: 0.6940,Test_f1: 0.6448,Train_acc: 0.7000,Test_acc: 0.6600\n",
      "Epoch: 096, Train_Loss: 0.6010,Test_Loss: 0.6055,Train_f1: 0.6940,Test_f1: 0.6448,Train_acc: 0.7000,Test_acc: 0.6600\n",
      "Epoch: 097, Train_Loss: 0.5984,Test_Loss: 0.6036,Train_f1: 0.6940,Test_f1: 0.6448,Train_acc: 0.7000,Test_acc: 0.6600\n",
      "Epoch: 098, Train_Loss: 0.5964,Test_Loss: 0.6019,Train_f1: 0.6940,Test_f1: 0.6448,Train_acc: 0.7000,Test_acc: 0.6600\n",
      "Epoch: 099, Train_Loss: 0.5946,Test_Loss: 0.6004,Train_f1: 0.6940,Test_f1: 0.6448,Train_acc: 0.7000,Test_acc: 0.6600\n",
      "Epoch: 100, Train_Loss: 0.5927,Test_Loss: 0.5987,Train_f1: 0.6940,Test_f1: 0.6389,Train_acc: 0.7000,Test_acc: 0.6533\n",
      "Epoch: 101, Train_Loss: 0.5896,Test_Loss: 0.5964,Train_f1: 0.6940,Test_f1: 0.6389,Train_acc: 0.7000,Test_acc: 0.6533\n",
      "Epoch: 102, Train_Loss: 0.5861,Test_Loss: 0.5937,Train_f1: 0.6940,Test_f1: 0.6389,Train_acc: 0.7000,Test_acc: 0.6533\n",
      "Epoch: 103, Train_Loss: 0.5837,Test_Loss: 0.5916,Train_f1: 0.6940,Test_f1: 0.6389,Train_acc: 0.7000,Test_acc: 0.6533\n",
      "Epoch: 104, Train_Loss: 0.5813,Test_Loss: 0.5893,Train_f1: 0.6940,Test_f1: 0.6448,Train_acc: 0.7000,Test_acc: 0.6600\n",
      "Epoch: 105, Train_Loss: 0.5793,Test_Loss: 0.5873,Train_f1: 0.6940,Test_f1: 0.6508,Train_acc: 0.7000,Test_acc: 0.6667\n",
      "Epoch: 106, Train_Loss: 0.5769,Test_Loss: 0.5852,Train_f1: 0.6940,Test_f1: 0.6508,Train_acc: 0.7000,Test_acc: 0.6667\n",
      "Epoch: 107, Train_Loss: 0.5744,Test_Loss: 0.5829,Train_f1: 0.7126,Test_f1: 0.6567,Train_acc: 0.7200,Test_acc: 0.6733\n",
      "Epoch: 108, Train_Loss: 0.5709,Test_Loss: 0.5802,Train_f1: 0.7313,Test_f1: 0.6627,Train_acc: 0.7400,Test_acc: 0.6800\n",
      "Epoch: 109, Train_Loss: 0.5674,Test_Loss: 0.5774,Train_f1: 0.7313,Test_f1: 0.6567,Train_acc: 0.7400,Test_acc: 0.6733\n",
      "Epoch: 110, Train_Loss: 0.5645,Test_Loss: 0.5747,Train_f1: 0.7313,Test_f1: 0.6686,Train_acc: 0.7400,Test_acc: 0.6867\n",
      "Epoch: 111, Train_Loss: 0.5616,Test_Loss: 0.5728,Train_f1: 0.7313,Test_f1: 0.6746,Train_acc: 0.7400,Test_acc: 0.6933\n",
      "Epoch: 112, Train_Loss: 0.5593,Test_Loss: 0.5708,Train_f1: 0.7313,Test_f1: 0.6806,Train_acc: 0.7400,Test_acc: 0.7000\n",
      "Epoch: 113, Train_Loss: 0.5582,Test_Loss: 0.5691,Train_f1: 0.6847,Test_f1: 0.6866,Train_acc: 0.7000,Test_acc: 0.7067\n",
      "Epoch: 114, Train_Loss: 0.5566,Test_Loss: 0.5680,Train_f1: 0.6847,Test_f1: 0.6866,Train_acc: 0.7000,Test_acc: 0.7067\n",
      "Epoch: 115, Train_Loss: 0.5568,Test_Loss: 0.5669,Train_f1: 0.6847,Test_f1: 0.6866,Train_acc: 0.7000,Test_acc: 0.7067\n",
      "Epoch: 116, Train_Loss: 0.5533,Test_Loss: 0.5654,Train_f1: 0.7313,Test_f1: 0.6866,Train_acc: 0.7400,Test_acc: 0.7067\n",
      "Epoch: 117, Train_Loss: 0.5513,Test_Loss: 0.5647,Train_f1: 0.7313,Test_f1: 0.6686,Train_acc: 0.7400,Test_acc: 0.6867\n",
      "Epoch: 118, Train_Loss: 0.5509,Test_Loss: 0.5644,Train_f1: 0.7126,Test_f1: 0.6567,Train_acc: 0.7200,Test_acc: 0.6733\n",
      "Epoch: 119, Train_Loss: 0.5504,Test_Loss: 0.5639,Train_f1: 0.7126,Test_f1: 0.6567,Train_acc: 0.7200,Test_acc: 0.6733\n",
      "Epoch: 120, Train_Loss: 0.5492,Test_Loss: 0.5628,Train_f1: 0.7126,Test_f1: 0.6567,Train_acc: 0.7200,Test_acc: 0.6733\n",
      "Epoch: 121, Train_Loss: 0.5469,Test_Loss: 0.5610,Train_f1: 0.7313,Test_f1: 0.6686,Train_acc: 0.7400,Test_acc: 0.6867\n",
      "Epoch: 122, Train_Loss: 0.5449,Test_Loss: 0.5596,Train_f1: 0.7313,Test_f1: 0.6746,Train_acc: 0.7400,Test_acc: 0.6933\n",
      "Epoch: 123, Train_Loss: 0.5427,Test_Loss: 0.5575,Train_f1: 0.7313,Test_f1: 0.6866,Train_acc: 0.7400,Test_acc: 0.7067\n",
      "Epoch: 124, Train_Loss: 0.5418,Test_Loss: 0.5565,Train_f1: 0.7083,Test_f1: 0.6866,Train_acc: 0.7200,Test_acc: 0.7067\n",
      "Epoch: 125, Train_Loss: 0.5404,Test_Loss: 0.5554,Train_f1: 0.7083,Test_f1: 0.6866,Train_acc: 0.7200,Test_acc: 0.7067\n",
      "Epoch: 126, Train_Loss: 0.5385,Test_Loss: 0.5541,Train_f1: 0.7083,Test_f1: 0.6866,Train_acc: 0.7200,Test_acc: 0.7067\n",
      "Epoch: 127, Train_Loss: 0.5366,Test_Loss: 0.5526,Train_f1: 0.6847,Test_f1: 0.6866,Train_acc: 0.7000,Test_acc: 0.7067\n",
      "Epoch: 128, Train_Loss: 0.5346,Test_Loss: 0.5511,Train_f1: 0.6847,Test_f1: 0.6866,Train_acc: 0.7000,Test_acc: 0.7067\n",
      "Epoch: 129, Train_Loss: 0.5321,Test_Loss: 0.5497,Train_f1: 0.6847,Test_f1: 0.6866,Train_acc: 0.7000,Test_acc: 0.7067\n",
      "Epoch: 130, Train_Loss: 0.5297,Test_Loss: 0.5485,Train_f1: 0.6847,Test_f1: 0.6866,Train_acc: 0.7000,Test_acc: 0.7067\n",
      "Epoch: 131, Train_Loss: 0.5276,Test_Loss: 0.5475,Train_f1: 0.7083,Test_f1: 0.6866,Train_acc: 0.7200,Test_acc: 0.7067\n",
      "Epoch: 132, Train_Loss: 0.5255,Test_Loss: 0.5467,Train_f1: 0.7083,Test_f1: 0.6866,Train_acc: 0.7200,Test_acc: 0.7067\n",
      "Epoch: 133, Train_Loss: 0.5235,Test_Loss: 0.5457,Train_f1: 0.7083,Test_f1: 0.6866,Train_acc: 0.7200,Test_acc: 0.7067\n",
      "Epoch: 134, Train_Loss: 0.5218,Test_Loss: 0.5449,Train_f1: 0.7083,Test_f1: 0.6866,Train_acc: 0.7200,Test_acc: 0.7067\n",
      "Epoch: 135, Train_Loss: 0.5200,Test_Loss: 0.5441,Train_f1: 0.7083,Test_f1: 0.6866,Train_acc: 0.7200,Test_acc: 0.7067\n",
      "Epoch: 136, Train_Loss: 0.5188,Test_Loss: 0.5436,Train_f1: 0.7083,Test_f1: 0.6866,Train_acc: 0.7200,Test_acc: 0.7067\n",
      "Epoch: 137, Train_Loss: 0.5178,Test_Loss: 0.5435,Train_f1: 0.7083,Test_f1: 0.6866,Train_acc: 0.7200,Test_acc: 0.7067\n",
      "Epoch: 138, Train_Loss: 0.5169,Test_Loss: 0.5433,Train_f1: 0.7083,Test_f1: 0.6866,Train_acc: 0.7200,Test_acc: 0.7067\n",
      "Epoch: 139, Train_Loss: 0.5162,Test_Loss: 0.5435,Train_f1: 0.7083,Test_f1: 0.6866,Train_acc: 0.7200,Test_acc: 0.7067\n",
      "Epoch: 140, Train_Loss: 0.5162,Test_Loss: 0.5442,Train_f1: 0.7313,Test_f1: 0.6866,Train_acc: 0.7400,Test_acc: 0.7067\n",
      "Epoch: 141, Train_Loss: 0.5154,Test_Loss: 0.5444,Train_f1: 0.7313,Test_f1: 0.6866,Train_acc: 0.7400,Test_acc: 0.7067\n",
      "Epoch: 142, Train_Loss: 0.5122,Test_Loss: 0.5430,Train_f1: 0.7313,Test_f1: 0.6866,Train_acc: 0.7400,Test_acc: 0.7067\n",
      "Epoch: 143, Train_Loss: 0.5085,Test_Loss: 0.5408,Train_f1: 0.7313,Test_f1: 0.6866,Train_acc: 0.7400,Test_acc: 0.7067\n",
      "Epoch: 144, Train_Loss: 0.5050,Test_Loss: 0.5382,Train_f1: 0.7083,Test_f1: 0.6866,Train_acc: 0.7200,Test_acc: 0.7067\n",
      "Epoch: 145, Train_Loss: 0.5025,Test_Loss: 0.5357,Train_f1: 0.7083,Test_f1: 0.6866,Train_acc: 0.7200,Test_acc: 0.7067\n",
      "Epoch: 146, Train_Loss: 0.4998,Test_Loss: 0.5328,Train_f1: 0.7083,Test_f1: 0.6866,Train_acc: 0.7200,Test_acc: 0.7067\n",
      "Epoch: 147, Train_Loss: 0.4985,Test_Loss: 0.5303,Train_f1: 0.6847,Test_f1: 0.6866,Train_acc: 0.7000,Test_acc: 0.7067\n",
      "Epoch: 148, Train_Loss: 0.4978,Test_Loss: 0.5291,Train_f1: 0.6604,Test_f1: 0.6699,Train_acc: 0.6800,Test_acc: 0.6933\n",
      "Epoch: 149, Train_Loss: 0.4978,Test_Loss: 0.5291,Train_f1: 0.6604,Test_f1: 0.6746,Train_acc: 0.6800,Test_acc: 0.6933\n",
      "Epoch: 150, Train_Loss: 0.4965,Test_Loss: 0.5293,Train_f1: 0.7126,Test_f1: 0.7175,Train_acc: 0.7200,Test_acc: 0.7267\n",
      "Epoch: 151, Train_Loss: 0.4952,Test_Loss: 0.5302,Train_f1: 0.7182,Test_f1: 0.7246,Train_acc: 0.7200,Test_acc: 0.7267\n",
      "Epoch: 152, Train_Loss: 0.4949,Test_Loss: 0.5310,Train_f1: 0.7596,Test_f1: 0.6867,Train_acc: 0.7600,Test_acc: 0.6867\n",
      "Epoch: 153, Train_Loss: 0.4950,Test_Loss: 0.5315,Train_f1: 0.7200,Test_f1: 0.6511,Train_acc: 0.7200,Test_acc: 0.6533\n",
      "Epoch: 154, Train_Loss: 0.4955,Test_Loss: 0.5324,Train_f1: 0.7391,Test_f1: 0.6199,Train_acc: 0.7400,Test_acc: 0.6267\n",
      "Epoch: 155, Train_Loss: 0.4962,Test_Loss: 0.5337,Train_f1: 0.7565,Test_f1: 0.6245,Train_acc: 0.7600,Test_acc: 0.6333\n",
      "Epoch: 156, Train_Loss: 0.4960,Test_Loss: 0.5347,Train_f1: 0.7756,Test_f1: 0.6245,Train_acc: 0.7800,Test_acc: 0.6333\n",
      "Epoch: 157, Train_Loss: 0.4946,Test_Loss: 0.5344,Train_f1: 0.7971,Test_f1: 0.6185,Train_acc: 0.8000,Test_acc: 0.6267\n",
      "Epoch: 158, Train_Loss: 0.4913,Test_Loss: 0.5335,Train_f1: 0.7971,Test_f1: 0.6409,Train_acc: 0.8000,Test_acc: 0.6467\n",
      "Epoch: 159, Train_Loss: 0.4874,Test_Loss: 0.5319,Train_f1: 0.7997,Test_f1: 0.6850,Train_acc: 0.8000,Test_acc: 0.6867\n",
      "Epoch: 160, Train_Loss: 0.4839,Test_Loss: 0.5294,Train_f1: 0.8000,Test_f1: 0.7065,Train_acc: 0.8000,Test_acc: 0.7067\n",
      "Epoch: 161, Train_Loss: 0.4810,Test_Loss: 0.5260,Train_f1: 0.7799,Test_f1: 0.7000,Train_acc: 0.7800,Test_acc: 0.7000\n",
      "Epoch: 162, Train_Loss: 0.4787,Test_Loss: 0.5234,Train_f1: 0.7799,Test_f1: 0.6999,Train_acc: 0.7800,Test_acc: 0.7000\n",
      "Epoch: 163, Train_Loss: 0.4764,Test_Loss: 0.5222,Train_f1: 0.7799,Test_f1: 0.7066,Train_acc: 0.7800,Test_acc: 0.7067\n",
      "Epoch: 164, Train_Loss: 0.4747,Test_Loss: 0.5217,Train_f1: 0.7799,Test_f1: 0.7000,Train_acc: 0.7800,Test_acc: 0.7000\n",
      "Epoch: 165, Train_Loss: 0.4732,Test_Loss: 0.5213,Train_f1: 0.7799,Test_f1: 0.7000,Train_acc: 0.7800,Test_acc: 0.7000\n",
      "Epoch: 166, Train_Loss: 0.4724,Test_Loss: 0.5228,Train_f1: 0.8199,Test_f1: 0.6928,Train_acc: 0.8200,Test_acc: 0.6933\n",
      "Epoch: 167, Train_Loss: 0.4711,Test_Loss: 0.5229,Train_f1: 0.7792,Test_f1: 0.6700,Train_acc: 0.7800,Test_acc: 0.6733\n",
      "Epoch: 168, Train_Loss: 0.4691,Test_Loss: 0.5212,Train_f1: 0.7792,Test_f1: 0.6637,Train_acc: 0.7800,Test_acc: 0.6667\n",
      "Epoch: 169, Train_Loss: 0.4684,Test_Loss: 0.5207,Train_f1: 0.7987,Test_f1: 0.6335,Train_acc: 0.8000,Test_acc: 0.6400\n",
      "Epoch: 170, Train_Loss: 0.4665,Test_Loss: 0.5187,Train_f1: 0.7792,Test_f1: 0.6637,Train_acc: 0.7800,Test_acc: 0.6667\n",
      "Epoch: 171, Train_Loss: 0.4654,Test_Loss: 0.5183,Train_f1: 0.7596,Test_f1: 0.6347,Train_acc: 0.7600,Test_acc: 0.6400\n",
      "Epoch: 172, Train_Loss: 0.4646,Test_Loss: 0.5182,Train_f1: 0.7391,Test_f1: 0.6199,Train_acc: 0.7400,Test_acc: 0.6267\n",
      "Epoch: 173, Train_Loss: 0.4642,Test_Loss: 0.5183,Train_f1: 0.7585,Test_f1: 0.6321,Train_acc: 0.7600,Test_acc: 0.6400\n",
      "Epoch: 174, Train_Loss: 0.4634,Test_Loss: 0.5186,Train_f1: 0.7565,Test_f1: 0.6486,Train_acc: 0.7600,Test_acc: 0.6600\n",
      "Epoch: 175, Train_Loss: 0.4616,Test_Loss: 0.5189,Train_f1: 0.7756,Test_f1: 0.6408,Train_acc: 0.7800,Test_acc: 0.6533\n",
      "Epoch: 176, Train_Loss: 0.4594,Test_Loss: 0.5184,Train_f1: 0.7756,Test_f1: 0.6486,Train_acc: 0.7800,Test_acc: 0.6600\n",
      "Epoch: 177, Train_Loss: 0.4566,Test_Loss: 0.5172,Train_f1: 0.7971,Test_f1: 0.6366,Train_acc: 0.8000,Test_acc: 0.6467\n",
      "Epoch: 178, Train_Loss: 0.4540,Test_Loss: 0.5158,Train_f1: 0.8182,Test_f1: 0.6366,Train_acc: 0.8200,Test_acc: 0.6467\n",
      "Epoch: 179, Train_Loss: 0.4511,Test_Loss: 0.5130,Train_f1: 0.7987,Test_f1: 0.6606,Train_acc: 0.8000,Test_acc: 0.6667\n",
      "Epoch: 180, Train_Loss: 0.4490,Test_Loss: 0.5095,Train_f1: 0.8193,Test_f1: 0.7123,Train_acc: 0.8200,Test_acc: 0.7133\n",
      "Epoch: 181, Train_Loss: 0.4477,Test_Loss: 0.5079,Train_f1: 0.8193,Test_f1: 0.7192,Train_acc: 0.8200,Test_acc: 0.7200\n",
      "Epoch: 182, Train_Loss: 0.4468,Test_Loss: 0.5078,Train_f1: 0.8193,Test_f1: 0.7192,Train_acc: 0.8200,Test_acc: 0.7200\n",
      "Epoch: 183, Train_Loss: 0.4460,Test_Loss: 0.5085,Train_f1: 0.8193,Test_f1: 0.7054,Train_acc: 0.8200,Test_acc: 0.7067\n",
      "Epoch: 184, Train_Loss: 0.4444,Test_Loss: 0.5079,Train_f1: 0.8193,Test_f1: 0.6914,Train_acc: 0.8200,Test_acc: 0.6933\n",
      "Epoch: 185, Train_Loss: 0.4429,Test_Loss: 0.5084,Train_f1: 0.8182,Test_f1: 0.6518,Train_acc: 0.8200,Test_acc: 0.6600\n",
      "Epoch: 186, Train_Loss: 0.4450,Test_Loss: 0.5116,Train_f1: 0.7947,Test_f1: 0.6346,Train_acc: 0.8000,Test_acc: 0.6533\n",
      "Epoch: 187, Train_Loss: 0.4469,Test_Loss: 0.5112,Train_f1: 0.7947,Test_f1: 0.6353,Train_acc: 0.8000,Test_acc: 0.6600\n",
      "Epoch: 188, Train_Loss: 0.4490,Test_Loss: 0.5100,Train_f1: 0.8140,Test_f1: 0.6470,Train_acc: 0.8200,Test_acc: 0.6733\n",
      "Epoch: 189, Train_Loss: 0.4496,Test_Loss: 0.5086,Train_f1: 0.8333,Test_f1: 0.6528,Train_acc: 0.8400,Test_acc: 0.6800\n",
      "Epoch: 190, Train_Loss: 0.4505,Test_Loss: 0.5072,Train_f1: 0.8108,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch 00192: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch: 191, Train_Loss: 0.4510,Test_Loss: 0.5066,Train_f1: 0.8108,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch: 192, Train_Loss: 0.4502,Test_Loss: 0.5060,Train_f1: 0.8108,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch: 193, Train_Loss: 0.4484,Test_Loss: 0.5050,Train_f1: 0.8108,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch: 194, Train_Loss: 0.4467,Test_Loss: 0.5041,Train_f1: 0.8108,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch: 195, Train_Loss: 0.4452,Test_Loss: 0.5035,Train_f1: 0.8108,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch: 196, Train_Loss: 0.4438,Test_Loss: 0.5031,Train_f1: 0.8333,Test_f1: 0.6614,Train_acc: 0.8400,Test_acc: 0.6867\n",
      "Epoch: 197, Train_Loss: 0.4423,Test_Loss: 0.5028,Train_f1: 0.8140,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch: 198, Train_Loss: 0.4407,Test_Loss: 0.5026,Train_f1: 0.7756,Test_f1: 0.6614,Train_acc: 0.7800,Test_acc: 0.6867\n",
      "Epoch: 199, Train_Loss: 0.4393,Test_Loss: 0.5027,Train_f1: 0.7756,Test_f1: 0.6555,Train_acc: 0.7800,Test_acc: 0.6800\n",
      "Epoch: 200, Train_Loss: 0.4379,Test_Loss: 0.5029,Train_f1: 0.7756,Test_f1: 0.6555,Train_acc: 0.7800,Test_acc: 0.6800\n",
      "Epoch: 201, Train_Loss: 0.4369,Test_Loss: 0.5031,Train_f1: 0.7756,Test_f1: 0.6496,Train_acc: 0.7800,Test_acc: 0.6733\n",
      "Epoch: 202, Train_Loss: 0.4360,Test_Loss: 0.5031,Train_f1: 0.7756,Test_f1: 0.6496,Train_acc: 0.7800,Test_acc: 0.6733\n",
      "Epoch: 203, Train_Loss: 0.4353,Test_Loss: 0.5031,Train_f1: 0.7947,Test_f1: 0.6496,Train_acc: 0.8000,Test_acc: 0.6733\n",
      "Epoch: 204, Train_Loss: 0.4342,Test_Loss: 0.5033,Train_f1: 0.7947,Test_f1: 0.6496,Train_acc: 0.8000,Test_acc: 0.6733\n",
      "Epoch: 205, Train_Loss: 0.4332,Test_Loss: 0.5031,Train_f1: 0.7947,Test_f1: 0.6496,Train_acc: 0.8000,Test_acc: 0.6733\n",
      "Epoch: 206, Train_Loss: 0.4324,Test_Loss: 0.5029,Train_f1: 0.7947,Test_f1: 0.6496,Train_acc: 0.8000,Test_acc: 0.6733\n",
      "Epoch: 207, Train_Loss: 0.4316,Test_Loss: 0.5027,Train_f1: 0.7947,Test_f1: 0.6438,Train_acc: 0.8000,Test_acc: 0.6667\n",
      "Epoch: 208, Train_Loss: 0.4310,Test_Loss: 0.5028,Train_f1: 0.7947,Test_f1: 0.6438,Train_acc: 0.8000,Test_acc: 0.6667\n",
      "Epoch: 209, Train_Loss: 0.4308,Test_Loss: 0.5030,Train_f1: 0.7947,Test_f1: 0.6438,Train_acc: 0.8000,Test_acc: 0.6667\n",
      "Epoch: 210, Train_Loss: 0.4302,Test_Loss: 0.5030,Train_f1: 0.7947,Test_f1: 0.6438,Train_acc: 0.8000,Test_acc: 0.6667\n",
      "Epoch: 211, Train_Loss: 0.4300,Test_Loss: 0.5032,Train_f1: 0.7947,Test_f1: 0.6438,Train_acc: 0.8000,Test_acc: 0.6667\n",
      "Epoch: 212, Train_Loss: 0.4296,Test_Loss: 0.5036,Train_f1: 0.7947,Test_f1: 0.6380,Train_acc: 0.8000,Test_acc: 0.6600\n",
      "Epoch: 213, Train_Loss: 0.4283,Test_Loss: 0.5037,Train_f1: 0.7947,Test_f1: 0.6404,Train_acc: 0.8000,Test_acc: 0.6600\n",
      "Epoch: 214, Train_Loss: 0.4272,Test_Loss: 0.5035,Train_f1: 0.7947,Test_f1: 0.6486,Train_acc: 0.8000,Test_acc: 0.6667\n",
      "Epoch: 215, Train_Loss: 0.4262,Test_Loss: 0.5032,Train_f1: 0.7947,Test_f1: 0.6588,Train_acc: 0.8000,Test_acc: 0.6733\n",
      "Epoch: 216, Train_Loss: 0.4254,Test_Loss: 0.5030,Train_f1: 0.8164,Test_f1: 0.6606,Train_acc: 0.8200,Test_acc: 0.6733\n",
      "Epoch: 217, Train_Loss: 0.4248,Test_Loss: 0.5033,Train_f1: 0.8164,Test_f1: 0.6624,Train_acc: 0.8200,Test_acc: 0.6733\n",
      "Epoch: 218, Train_Loss: 0.4245,Test_Loss: 0.5032,Train_f1: 0.8377,Test_f1: 0.6546,Train_acc: 0.8400,Test_acc: 0.6667\n",
      "Epoch: 219, Train_Loss: 0.4245,Test_Loss: 0.5037,Train_f1: 0.8164,Test_f1: 0.6546,Train_acc: 0.8200,Test_acc: 0.6667\n",
      "Epoch: 220, Train_Loss: 0.4247,Test_Loss: 0.5038,Train_f1: 0.8164,Test_f1: 0.6588,Train_acc: 0.8200,Test_acc: 0.6733\n",
      "Epoch: 221, Train_Loss: 0.4252,Test_Loss: 0.5042,Train_f1: 0.7947,Test_f1: 0.6404,Train_acc: 0.8000,Test_acc: 0.6600\n",
      "Epoch: 222, Train_Loss: 0.4258,Test_Loss: 0.5036,Train_f1: 0.7947,Test_f1: 0.6438,Train_acc: 0.8000,Test_acc: 0.6667\n",
      "Epoch: 223, Train_Loss: 0.4266,Test_Loss: 0.5032,Train_f1: 0.7947,Test_f1: 0.6411,Train_acc: 0.8000,Test_acc: 0.6667\n",
      "Epoch: 224, Train_Loss: 0.4268,Test_Loss: 0.5029,Train_f1: 0.8140,Test_f1: 0.6411,Train_acc: 0.8200,Test_acc: 0.6667\n",
      "Epoch 00226: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch: 225, Train_Loss: 0.4274,Test_Loss: 0.5026,Train_f1: 0.8140,Test_f1: 0.6528,Train_acc: 0.8200,Test_acc: 0.6800\n",
      "Epoch: 226, Train_Loss: 0.4279,Test_Loss: 0.5025,Train_f1: 0.8140,Test_f1: 0.6528,Train_acc: 0.8200,Test_acc: 0.6800\n",
      "Epoch: 227, Train_Loss: 0.4283,Test_Loss: 0.5023,Train_f1: 0.8333,Test_f1: 0.6528,Train_acc: 0.8400,Test_acc: 0.6800\n",
      "Epoch: 228, Train_Loss: 0.4285,Test_Loss: 0.5022,Train_f1: 0.8333,Test_f1: 0.6528,Train_acc: 0.8400,Test_acc: 0.6800\n",
      "Epoch: 229, Train_Loss: 0.4281,Test_Loss: 0.5016,Train_f1: 0.8333,Test_f1: 0.6614,Train_acc: 0.8400,Test_acc: 0.6867\n",
      "Epoch: 230, Train_Loss: 0.4278,Test_Loss: 0.5012,Train_f1: 0.8333,Test_f1: 0.6614,Train_acc: 0.8400,Test_acc: 0.6867\n",
      "Epoch: 231, Train_Loss: 0.4276,Test_Loss: 0.5007,Train_f1: 0.8333,Test_f1: 0.6614,Train_acc: 0.8400,Test_acc: 0.6867\n",
      "Epoch 00233: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch: 232, Train_Loss: 0.4271,Test_Loss: 0.5002,Train_f1: 0.8333,Test_f1: 0.6614,Train_acc: 0.8400,Test_acc: 0.6867\n",
      "Epoch: 233, Train_Loss: 0.4268,Test_Loss: 0.4998,Train_f1: 0.8333,Test_f1: 0.6614,Train_acc: 0.8400,Test_acc: 0.6867\n",
      "Epoch: 234, Train_Loss: 0.4265,Test_Loss: 0.4996,Train_f1: 0.8333,Test_f1: 0.6614,Train_acc: 0.8400,Test_acc: 0.6867\n",
      "Epoch: 235, Train_Loss: 0.4265,Test_Loss: 0.4996,Train_f1: 0.8333,Test_f1: 0.6614,Train_acc: 0.8400,Test_acc: 0.6867\n",
      "Epoch: 236, Train_Loss: 0.4264,Test_Loss: 0.4996,Train_f1: 0.8333,Test_f1: 0.6614,Train_acc: 0.8400,Test_acc: 0.6867\n",
      "Epoch: 237, Train_Loss: 0.4262,Test_Loss: 0.4996,Train_f1: 0.8333,Test_f1: 0.6614,Train_acc: 0.8400,Test_acc: 0.6867\n",
      "Epoch: 238, Train_Loss: 0.4259,Test_Loss: 0.4997,Train_f1: 0.8333,Test_f1: 0.6614,Train_acc: 0.8400,Test_acc: 0.6867\n",
      "Epoch 00240: reducing learning rate of group 0 to 3.1250e-05.\n",
      "Epoch: 239, Train_Loss: 0.4254,Test_Loss: 0.4996,Train_f1: 0.8333,Test_f1: 0.6614,Train_acc: 0.8400,Test_acc: 0.6867\n",
      "Epoch: 240, Train_Loss: 0.4251,Test_Loss: 0.4996,Train_f1: 0.8333,Test_f1: 0.6614,Train_acc: 0.8400,Test_acc: 0.6867\n",
      "Epoch: 241, Train_Loss: 0.4248,Test_Loss: 0.4995,Train_f1: 0.8333,Test_f1: 0.6614,Train_acc: 0.8400,Test_acc: 0.6867\n",
      "Epoch: 242, Train_Loss: 0.4245,Test_Loss: 0.4995,Train_f1: 0.8333,Test_f1: 0.6614,Train_acc: 0.8400,Test_acc: 0.6867\n",
      "Epoch: 243, Train_Loss: 0.4243,Test_Loss: 0.4995,Train_f1: 0.8140,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch: 244, Train_Loss: 0.4240,Test_Loss: 0.4997,Train_f1: 0.8140,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch: 245, Train_Loss: 0.4239,Test_Loss: 0.4997,Train_f1: 0.8140,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch: 246, Train_Loss: 0.4237,Test_Loss: 0.4997,Train_f1: 0.8140,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch: 247, Train_Loss: 0.4235,Test_Loss: 0.4997,Train_f1: 0.8140,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch: 248, Train_Loss: 0.4233,Test_Loss: 0.4997,Train_f1: 0.8140,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch: 249, Train_Loss: 0.4231,Test_Loss: 0.4997,Train_f1: 0.8140,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch: 250, Train_Loss: 0.4229,Test_Loss: 0.4996,Train_f1: 0.8140,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch: 251, Train_Loss: 0.4227,Test_Loss: 0.4996,Train_f1: 0.8140,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch: 252, Train_Loss: 0.4224,Test_Loss: 0.4995,Train_f1: 0.8140,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch: 253, Train_Loss: 0.4222,Test_Loss: 0.4994,Train_f1: 0.8140,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch: 254, Train_Loss: 0.4219,Test_Loss: 0.4994,Train_f1: 0.8140,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch: 255, Train_Loss: 0.4217,Test_Loss: 0.4993,Train_f1: 0.8140,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch: 256, Train_Loss: 0.4215,Test_Loss: 0.4993,Train_f1: 0.8140,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch: 257, Train_Loss: 0.4213,Test_Loss: 0.4993,Train_f1: 0.8140,Test_f1: 0.6614,Train_acc: 0.8200,Test_acc: 0.6867\n",
      "Epoch: 258, Train_Loss: 0.4211,Test_Loss: 0.4993,Train_f1: 0.8140,Test_f1: 0.6555,Train_acc: 0.8200,Test_acc: 0.6800\n",
      "Epoch: 259, Train_Loss: 0.4209,Test_Loss: 0.4992,Train_f1: 0.8140,Test_f1: 0.6555,Train_acc: 0.8200,Test_acc: 0.6800\n",
      "Epoch: 260, Train_Loss: 0.4206,Test_Loss: 0.4991,Train_f1: 0.8140,Test_f1: 0.6555,Train_acc: 0.8200,Test_acc: 0.6800\n",
      "Epoch: 261, Train_Loss: 0.4204,Test_Loss: 0.4990,Train_f1: 0.8140,Test_f1: 0.6555,Train_acc: 0.8200,Test_acc: 0.6800\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m train()\n\u001b[1;32m      5\u001b[0m train_macro_f1, train_acc, train_loss \u001b[39m=\u001b[39m test(train_loader)\n\u001b[0;32m----> 6\u001b[0m test_macro_f1, test_acc, test_loss \u001b[39m=\u001b[39m test(test_loader)\n\u001b[1;32m      7\u001b[0m scheduler\u001b[39m.\u001b[39mstep(train_loss)\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[1;32m      9\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m:\u001b[39;00m\u001b[39m03d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Train_Loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m02.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m,Test_Loss: \u001b[39m\u001b[39m{\u001b[39;00mtest_loss\u001b[39m:\u001b[39;00m\u001b[39m02.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m,Train_f1: \u001b[39m\u001b[39m{\u001b[39;00mtrain_macro_f1\u001b[39m:\u001b[39;00m\u001b[39m01.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m,Test_f1: \u001b[39m\u001b[39m{\u001b[39;00mtest_macro_f1\u001b[39m:\u001b[39;00m\u001b[39m01.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m,Train_acc: \u001b[39m\u001b[39m{\u001b[39;00mtrain_acc\u001b[39m:\u001b[39;00m\u001b[39m01.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m,Test_acc: \u001b[39m\u001b[39m{\u001b[39;00mtest_acc\u001b[39m:\u001b[39;00m\u001b[39m01.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m~/venvs/MLG/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "Cell \u001b[0;32mIn[30], line 21\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     19\u001b[0m y_true \u001b[39m=\u001b[39m []\n\u001b[1;32m     20\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m loader:\n\u001b[1;32m     22\u001b[0m     y_out\u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     23\u001b[0m     y_pred\u001b[39m.\u001b[39mappend(y_out\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/venvs/MLG/lib/python3.9/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/venvs/MLG/lib/python3.9/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/venvs/MLG/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/venvs/MLG/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Projects/2023L-machine-learning-on-graphs/project_2/utils.py:140\u001b[0m, in \u001b[0;36mGraphDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m--> 140\u001b[0m     data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(path\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00midx\u001b[39m}\u001b[39;49;00m\u001b[39m.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    141\u001b[0m     data\u001b[39m.\u001b[39my \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels[idx] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    142\u001b[0m     \u001b[39m# to -1 bo na https://www.timeseriesclassification.com/ klasy zawsze zaczynają numerację od 1 a my chcemy od 0\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/MLG/lib/python3.9/site-packages/torch/serialization.py:797\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m     \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m     \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m     \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m     orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n\u001b[0;32m--> 797\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_reader(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    798\u001b[0m         \u001b[39mif\u001b[39;00m _is_torchscript_zip(opened_zipfile):\n\u001b[1;32m    799\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m received a zip file that looks like a TorchScript archive\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    800\u001b[0m                           \u001b[39m\"\u001b[39m\u001b[39m dispatching to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.jit.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m (call \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.jit.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m directly to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    801\u001b[0m                           \u001b[39m\"\u001b[39m\u001b[39m silence this warning)\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mUserWarning\u001b[39;00m)\n",
      "File \u001b[0;32m~/venvs/MLG/lib/python3.9/site-packages/torch/serialization.py:283\u001b[0m, in \u001b[0;36m_open_zipfile_reader.__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name_or_buffer) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 283\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49mPyTorchFileReader(name_or_buffer))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(1000):\n",
    "    train()\n",
    "    train_macro_f1, train_acc, train_loss = test(train_loader)\n",
    "    test_macro_f1, test_acc, test_loss = test(test_loader)\n",
    "    scheduler.step(train_loss)\n",
    "    print(\n",
    "        f\"Epoch: {epoch:03d}, Train_Loss: {train_loss:02.4f},Test_Loss: {test_loss:02.4f},Train_f1: {train_macro_f1:01.4f},Test_f1: {test_macro_f1:01.4f},Train_acc: {train_acc:01.4f},Test_acc: {test_acc:01.4f}\"\n",
    "    )\n",
    "    if test_macro_f1 > best_macro_f1:\n",
    "        best_accuracy = test_macro_f1\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), \"../data/best_model.pth\")\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
